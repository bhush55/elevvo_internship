{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941652fa-8fe4-4583-917d-219cbe5cf5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fdd26c-b310-4370-8599-39cde3bbac50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b062ad8-7213-407a-8aaf-b3b5c06b5f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec93939-9162-48f2-9e23-8680aba1b157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c42a06-3943-4a8f-8476-291568166cdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "#  Imports\n",
    "# ============================\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0044af-b1a1-4201-a4f6-d63df717838d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datasets extracted to: ./data_task8\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "#  Unzip datasets\n",
    "# ============================\n",
    "# Paths to your datasets (update if needed)\n",
    "dataset1_path = \"dataset_1.zip\"\n",
    "dataset2_path = \"dataset_2.zip\"\n",
    "extract_path = \"./data_task8\"\n",
    "\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Extract both datasets\n",
    "for dataset in [dataset1_path, dataset2_path]:\n",
    "    with zipfile.ZipFile(dataset, \"r\") as z:\n",
    "        z.extractall(extract_path)\n",
    "\n",
    "print(\"✅ Datasets extracted to:\", extract_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a214ae32-68dc-49d2-85af-15307eabb969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Jobs dataset loaded: job_descriptions.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "#  Load data (fixed)\n",
    "# ============================\n",
    "# Load resumes dataset\n",
    "resumes_df = None\n",
    "jobs_df = None\n",
    "\n",
    "for root, _, files in os.walk(extract_path):\n",
    "    for f in files:\n",
    "        file_path = os.path.join(root, f)\n",
    "        if \"resume\" in f.lower():\n",
    "            try:\n",
    "                resumes_df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "            except UnicodeDecodeError:\n",
    "                resumes_df = pd.read_csv(file_path, encoding=\"latin1\")\n",
    "            print(\"✅ Resumes dataset loaded:\", f)\n",
    "        elif \"job\" in f.lower():\n",
    "            try:\n",
    "                jobs_df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "            except UnicodeDecodeError:\n",
    "                jobs_df = pd.read_csv(file_path, encoding=\"latin1\")\n",
    "            print(\"✅ Jobs dataset loaded:\", f)\n",
    "\n",
    "print(\"Resumes shape:\", resumes_df.shape)\n",
    "print(\"Jobs shape:\", jobs_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05291e6-154f-4752-8301-bef6e89cd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Detect important columns\n",
    "# ============================\n",
    "def detect_column(df, candidates):\n",
    "    for col in candidates:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    raise KeyError(f\"None of {candidates} found in dataset!\")\n",
    "\n",
    "# Resume text\n",
    "resume_col = detect_column(resumes_df, [\"Resume\", \"Resume_str\", \"CV\", \"Text\"])\n",
    "\n",
    "# Job description\n",
    "job_col = detect_column(jobs_df, [\"Job Description\", \"JobDescription\", \"Description\", \"Responsibilities\", \"RoleDescription\"])\n",
    "\n",
    "# Job title\n",
    "job_title_col = detect_column(jobs_df, [\"Job Title\", \"Role\", \"Title\", \"Position\"])\n",
    "\n",
    "print(\"✅ Using resume column:\", resume_col)\n",
    "print(\"✅ Using job column:\", job_col)\n",
    "print(\"✅ Using job title column:\", job_title_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be223a60-cf41-4dae-b0ca-869b0be5e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "#  Skill extractor (simple rule-based)\n",
    "# ============================\n",
    "def extract_skills(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    keywords = [\n",
    "        \"python\", \"java\", \"sql\", \"excel\", \"power bi\", \"tableau\", \n",
    "        \"ml\", \"machine learning\", \"deep learning\", \"nlp\", \"c++\", \n",
    "        \"aws\", \"azure\", \"spark\", \"hadoop\", \"keras\", \"pytorch\", \"tensorflow\"\n",
    "    ]\n",
    "    text_lower = text.lower()\n",
    "    return [kw for kw in keywords if kw in text_lower]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37cca9-a7b3-4d8c-8e53-beab14351a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "#  Embedding Model\n",
    "# ============================\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"✅ Model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5f8ef-c1b7-4371-855d-327968957806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "#  Precompute Embeddings\n",
    "# ============================\n",
    "resumes_texts = resumes_df[resume_col].astype(str).tolist()\n",
    "jobs_texts = (jobs_df[job_col].astype(str) + \" \" + jobs_df.get(\"skills\", \"\").astype(str)).tolist()\n",
    "\n",
    "resume_embeddings = model.encode(resumes_texts, batch_size=32, show_progress_bar=True)\n",
    "job_embeddings = model.encode(jobs_texts, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "print(\"✅ Embeddings created:\", resume_embeddings.shape, job_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7c8ef-82d6-46c3-b71a-5507f3617f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "#  Matching & Ranking \n",
    "# ============================\n",
    "similarity_matrix = cosine_similarity(resume_embeddings, job_embeddings)\n",
    "\n",
    "results = []\n",
    "N = 5  # top resumes per job\n",
    "\n",
    "for j_idx, job in tqdm(jobs_df.iterrows(), total=len(jobs_df), desc=\"Matching Jobs\"):\n",
    "    sims = similarity_matrix[:, j_idx]\n",
    "    top_indices = np.argsort(sims)[::-1][:N]\n",
    "    \n",
    "    for rank, r_idx in enumerate(top_indices, start=1):\n",
    "        resume_text = resumes_df.iloc[r_idx][resume_col]\n",
    "        \n",
    "        score = round(sims[r_idx] * 100, 2)\n",
    "\n",
    "        # Skill overlap\n",
    "        resume_skills = set(extract_skills(resume_text))\n",
    "        jd_skills = set(extract_skills(job[job_col] + \" \" + str(job.get(\"skills\", \"\"))))\n",
    "        \n",
    "        matched = resume_skills & jd_skills\n",
    "        missing = jd_skills - resume_skills\n",
    "\n",
    "        results.append({\n",
    "            \"JobID\": job.get(\"Job Id\", j_idx),\n",
    "            \"JobRole\": job.get(job_title_col, f\"Job_{j_idx}\"),\n",
    "            \"CandidateID\": resumes_df.iloc[r_idx].get(\"CandidateID\", r_idx),\n",
    "            \"ResumeSnippet\": str(resume_text)[:150] + \"...\",\n",
    "            \"Score\": score,\n",
    "            \"MatchedSkills\": \", \".join(matched),\n",
    "            \"MissingSkills\": \", \".join(missing),\n",
    "            \"Rank\": rank\n",
    "        })\n",
    "\n",
    "top_matches_df = pd.DataFrame(results)\n",
    "top_matches_df.to_csv(\"topN_job_matches.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Matching completed! Top {N} resumes saved to topN_job_matches.csv\")\n",
    "top_matches_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e6292a-c86b-4bc1-8fcc-00c718dc6a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08552e0-5882-4fb3-9655-4b710e47fd86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a93f50-9612-4c34-8987-94461944d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bonus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9c097-ec38-438f-9acd-2681d8e1b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import joblib\n",
    "\n",
    "# Load job dataset\n",
    "jobs = pd.read_csv(\"dataset_2.csv\")   # your job dataset file\n",
    "jobs = jobs[['Job Title','Job Description','skills']].dropna()\n",
    "jobs['combined'] = jobs['Job Title'] + \" \" + jobs['Job Description'] + \" \" + jobs['skills']\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode job descriptions\n",
    "job_embeddings = model.encode(jobs['combined'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Save jobs + embeddings + model\n",
    "joblib.dump(jobs, \"jobs_dataset.pkl\")\n",
    "joblib.dump(job_embeddings, \"job_embeddings.pkl\")\n",
    "model.save(\"resume_model\")\n",
    "print(\"✅ Jobs and embeddings saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da569a-83b8-47e7-b52a-f9fdb6cc0c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mp_env)",
   "language": "python",
   "name": "mp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
